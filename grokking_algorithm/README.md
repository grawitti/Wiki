# **Грокаем алгоритмы**

## **О-большое**

**О-большое** определяет количество операций в *худшем случае*.

> Записывается как `O(n)`, где `n` число операций.

Основные примеры О-большого:

+ `O(log n)` - логарифмическое время. Пример: бинарный поиск.
+ `O(n)` - линейное время. Пример: Простой поиск.
+ `O(n * log n)` - Пример: эффективные алгоритмы сортировки.
+ `O(n * n)` - Пример: медленные алгоритмы сортировки (сортировка выбором).
+ `O(n!)` - Пример: очень медленные алгоритмы (задача о комивояжоре).

По сути формула описывает, насколько быстро возрастает время выполнения алгоритма с увеличением размера входных данных.

## Алгоритмы поиска

### Бинарный поиск (Binary search)

**Время выполнения**: `O(log n)`

Бинарный поиск агоритм поиска в отсортированном массиве, при каждой итерации размер массива сокращается в два раза.

> Бинарный поиск работает только с отсортированными массивами.

Пример: Дан массив: [2, 1, 5, 4, 8], необходимо найти индекс элемента со значением = 1.

нижний элемент = 0
верхний элемент = 4

средний элемент = (нижний элемент + верхний элемент) / 2 = (0 + 4) / 2 = 2

если средний элемент == заданному значению то возвращаяем индекс среднего элемента.
Иначе проверяем если средний элемент > искомого, то верхний элемент = средний элемент(2) - 1 = 1,
иначе нижний элемент равен средний элемент(2) + 1 = 3. На последующих итерациях делаем тоже самое
пока не будет найден нужный элемент или возвращаем код ошибки.

## Алгоритмы сортировки

### Сортировка выбором (Selection Sort)

Сортировка выбором заключается в выборе наименьшего/наибольшего элемента из входного массива,
добавления его в новый массив и удаление его же из входного массива.

**Время выполнения**: `O(n * n)`

Пример: Дан не отсортированный массив: [2, 1, 5, 4].

| Входной массив | Отсортированный массив |
|-----------------------------------------|
| [2, 1, 5, 4]   |[]                      |
| [2, 5, 4]      |[1]                     |
| [5, 4]         |[1, 2]                  |
| [5]            |[1, 2, 4]               |
| []             |[1, 2, 4, 5]            |

### Быстрая сортировка (Quick sort)

**Время выполнения**: `O(n * log n)`

Быстрая сортировка это рекурсивный алгоритм основанный на принципе **разделяй и властвуй**.

Стратегия **разделяй и властвуй** основана на разбиении задачи на уменьшающиеся фрагменты.

Решение задач методом **разделяй и властвуй** состоит из двух шагов:
- определить базовый случай, простейший случай из всех вохможных,
- задача делится или сокращается до тех пор, пока не будет сведена к базовому случаю.

Базовый случай алгоритма: когда массив пуст или состоит из одного элемента. Возможно добавить как базовый случай еще и массив с 2мя элементами.

Рекурсивный случай: когда элементов массива больше 1го.

Вначале выбирается опорный элемент из входного массива, например средний элемент или случайный элемент. Затем входной массив разделяется на два подмассива первый с элементами меньше чем опорный элемент, а второй с элементами больше чем опорный элемент. Вызов алгоритма выполняется рукурсивно для каждого подмассива пока не будет достигнут базовый случай. Вконце возвращается массив состоящий из [подмасиив с элементами меньше опороного] <опорный элемент> [подмассив с элементами больше опорного].

Пример: Дан не отсортированный массив: [2, 1, 5, 4, 0].

Опормым будем брать средний элемент.
1 вызов для входного массива:
[2, 1, 4, 0] <5> []
2 вызов для подмассива с элементами < 5:
[0] <1> [2, 4]
3 вызов для подмассива > 1:
[] <2> [4]

3й вызов возвращает массив: [2, 4]
2й вызов возвращает массив: [0, 1, 2, 4]
1й вызов возвращает массив: [0, 1, 2, 4, 5]

## Алгоритмы поиска для графов

### Поиск в ширину

Время выполения: `O(N+R)`, где:
- N - количество узлов (nodes)
- E - количество ребер (edges)

**Поиск в ширину** позволяет определить существует ли путь от узла А к узлу Б в графе,
если путь существует то находит кратчайший путь, т.е. такой путь в котором наименьшее 
количество сегментов.

Реализация:
- создаём список поиска используя двунаправленную очередь (deque)
- добаляем в очередь соседей корневого узла графа
- создаём список для проверенных узлов
- в цикле, пока очередь поиска не будет пустой:
- извлекаем из очереди поиска первый(очередной) узел
- проверяем что он еще не был проверен
- проверяем не удовлетворяет ли узел условиям поиска
- елси узел удовлетворяет условиям поиска, то возвращаем результат
- иначе добавляем соседей узла в список поиска
- добавляем узел в список проверенных узлов
- переходим к следующей итерации цикла...

### Алгоритм Дейкстры

> Алгоритм **Дейкстры** работает только с *направленными ациклическими взвешенными графами* 
Direct Acyclic Graph (DAG), в которых нет ребер с отрицательными весами.

> Для вычисления кратчайшего пути во взвешенном направленном графе, содержащем отрицательные 
веса ребер необходимо воспользоваться алгоритмом **Беллмана-Форда**.

Алгоритм:

1. Найти узел с наименьшим весом
1. Проверить, существует ли путь имеющий меньший вес к соседям этого узла, если существует,
обновить их стоимости
1. Повторять, это для всех узлов графа
1. Вычислить итоговый путь

## Жадные алгоритмы

**Жадный алгоритм** (greedy algorithm) — это алгоритм, который на каждом шагу делает локально наилучший выбор в надежде, что итоговое решение будет оптимальным.

К примеру, *алгоритм Дейкстры* нахождения кратчайшего пути в графе вполне себе жадный, потому что мы на каждом шагу ищем вершину с наименьшим весом, в которой мы еще не бывали, после чего обновляем значения других вершин. При этом можно доказать, что кратчайшие пути, найденные в вершинах, являются оптимальными.

### NP-полные задачи

**NP-полные задачи** - класс задач для которых **НЕ** существуют «быстрые» алгоритмы решения (время работы которых полиномиально зависит от размера входных данных).

Такие задачи принято решать *приближенными алгоритмами*.

#### Признаки NP-полных задач

- ваш алгоритм быстро работает при малом количестве элементов, но сильно замедляется при увеличении их числа;

- формулировка "все комбинации Х" часто указывает на NP-полную задачу;

- вам приходится вычислять все возможные варианты Х, потому что задачу невозможно разбить на меньшие подзадачи;

- если в задаче встречается некоторая последовательность (например, последовательноть городов, как в задаче о комивояжоре) и задача не имеет простого решения;

- если в задаче встречается некоторое множество и задача не имеет простого решения;

- можно ли преформулировать задачу в условиях задачи покрытия множества или задачи о комивояжоре.

### Приближённые алгоритмы

**Приближенный алгоритм** - это *жадный алгоритм* для решения *NP-полных задач*, который на каждом шаге находит *оптимальное решение*, в расчёте на то что будет достигнут *глобальный оптумум*.

## Динамическое программирование

*Динамическое программирование работает только в том случае, если каждая подзадача автономна, то есть не зависит от других подзадач.*

*Динамическое программирование применяется для оптимизации какой-либо характеристики при заданных ограничениях.*

### Рекомендации для решения задач с использованием динамического программирования

- в каждом решении из области динамического программирования строится таблица;
- значение ячеек таблицы обычно соответствует оптиизируемой характеристике. Например стоимость в задаче о рюкзаке.
- каждая ячейка представляет подзадачу, поэтому вы должны подумать о том, как разбить задачу на подзадачи.

### Где используется динамическое программирование:

- команда `diff` в `git`;
- *Растояние Левенштейна* - на сколько похожи две строки, проверка орфографии;
- перенос строк в *Microsoft Word*

### Нахождение самой длинной общей подстроки

Допустим пользователь ввёл `hish`, какое слово он имел ввиду `fish` или `vista`?

Алгоритм:
- если буква не совпадает значение 0
- если совпадает то значение равно значению наверху слева + 1

Таблица для fish:

|   | H | I | S | H |
|---|---|---|---|---|
| F | 0 | 0 | 0 | 0 |
| I | 0 | 1 | 0 | 0 |
| S | 0 | 0 | 2 | 0 |
| H | 0 | 0 | 0 | **3** |

Самая длинная общая подстрока для `hish` и `fish` = 3.

Таблица для vista:

|   | H | I | S | H |
|---|---|---|---|---|
| V | 0 | 0 | 0 | 0 |
| I | 0 | 1 | 0 | 0 |
| S | 0 | 0 | **2** | 0 |
| T | 0 | 0 | 0 | 0 |
| A | 0 | 0 | 0 | 0 |

Самая длинная общая подстрока для `hish` и `vista` = 2.

Получется `fish` больше подходит чем `vista` так как имеет более блинную общую подстроку с `hish`.

Псевдокод:
```python
if word_a[i] == word_b[j]:
    cell[i][j] = cell[i-1][j-1] + 1
else:
    cell[i][j] = 0
```

### Самая длинная общая последовательность

Допустим пользователь ввёл `fosh`, какое слово он имел ввиду `fish` или `fort`?

Алгоритм:
- если буква не совпадает выбрать большее значение
- если совпадает то значение равно значению наверху слева + 1

Таблица для fish:

|   | F | O | S | H |
|---|---|---|---|---|
| F | 1 | 1 | 1 | 1 |
| I | 1 | 1 | 1 | 1 |
| S | 1 | 1 | 2 | 2 |
| H | 1 | 1 | 1 | **3** |

Самая длинная общая поледовательнось для `fosh` и `fish` = 3.

Таблица для fort:

|   | F | O | S | H |
|---|---|---|---|---|
| F | 1 | 1 | 1 | 1 |
| O | 1 | 2 | 2 | 2 |
| R | 1 | 2 | 2 | 2 |
| T | 1 | 2 | 2 | **2** |

Самая длинная общая поледовательнось для `fosh` и `fort` = 2.

Плучается `fish` больше подходит так как имеет большую общую последовательность, чем `fort`.

Псевдокод:
```python
if word_a[i] == word_b[j]:
    cell[i][j] = cell[i-1][j-1] + 1
else:
    cell[i][j] = max(cell[i-1][j], cell[i][j-1])
```

## Алгоритм *k* ближайших соседей

**Алгоритм *k* ближайших соседей** применяется для классификации и регресии.

*Классификация* - распределение по категориям. Например в рекомендательной системе это пользователи со схожими вкусами.

 Для классификации можно использовать *растояние между точками* вычисляемое по формуле *Пифагора*:
 > `Корень((x1-x2)^2 + (y1-y2)^2)`
 где `x1` и `y1` это какие-то признаки 1го сравниваемого объекта, `x2` и `y2` - признаки 2го объекта.

*Регрессия* - прогнозирование результатов. В рекомендательной системе это прогнозирование оценки пользователя на основании средней оценки его ближайших соседей.

*Извлечение признаков* - преобразование элемента (например, фрукта или пользователя) в список чисел, которые могут использоваться для сравнения.